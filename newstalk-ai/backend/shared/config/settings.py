"""
ðŸŽ¯ NewsTalk AI í†µí•© ì„¤ì • ì‹œìŠ¤í…œ
===============================

ìˆœí™˜ ì˜ì¡´ì„± í•´ê²°ê³¼ í™˜ê²½ë³„ ì„¤ì • ê´€ë¦¬ë¥¼ ìœ„í•œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì„¤ì • ì‹œìŠ¤í…œ:
- í™˜ê²½ë³„ ì„¤ì • ìžë™ ë¡œë“œ (dev, staging, prod)
- ì„¤ì • ê²€ì¦ ë° íƒ€ìž… ì•ˆì „ì„±
- ë™ì  ì„¤ì • ì—…ë°ì´íŠ¸ ì§€ì›
- ë³´ì•ˆ ì„¤ì • ì•”í˜¸í™”
- ì„¤ì • ë³€ê²½ ì¶”ì  ë° ê°ì‚¬
- íŽ˜ì¼ì˜¤ë²„ ë° ë³µêµ¬ ì„¤ì •
"""
import os
import json
import logging
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Union, Type
from pathlib import Path
from enum import Enum
import yaml
from pydantic import BaseSettings, validator, Field
from pydantic.env_settings import SettingsSourceCallable
import redis
import asyncio
from datetime import datetime, timedelta
import hashlib

logger = logging.getLogger(__name__)

class Environment(Enum):
    """í™˜ê²½ íƒ€ìž…"""
    DEVELOPMENT = "development"
    STAGING = "staging"
    PRODUCTION = "production"
    TESTING = "testing"

class LogLevel(Enum):
    """ë¡œê·¸ ë ˆë²¨"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

@dataclass
class DatabaseSettings:
    """ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •"""
    host: str = "localhost"
    port: int = 5432
    database: str = "newstalk_ai"
    username: str = "postgres"
    password: str = ""
    
    # ì—°ê²° í’€ ì„¤ì •
    min_pool_size: int = 5
    max_pool_size: int = 20
    pool_timeout: float = 30.0
    pool_recycle: int = 3600
    
    # ì„±ëŠ¥ ì„¤ì •
    enable_query_cache: bool = True
    cache_ttl_seconds: int = 300
    slow_query_threshold: float = 1.0
    
    # ë³µì œë³¸ ì„¤ì •
    enable_read_replica: bool = False
    read_replica_urls: List[str] = field(default_factory=list)
    
    # SSL ì„¤ì •
    ssl_mode: str = "prefer"
    ssl_cert: Optional[str] = None
    ssl_key: Optional[str] = None
    ssl_ca: Optional[str] = None
    
    def get_database_url(self, for_replica: bool = False) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ URL ìƒì„±"""
        if for_replica and self.read_replica_urls:
            return self.read_replica_urls[0]  # ì²« ë²ˆì§¸ ë³µì œë³¸ ì‚¬ìš©
        
        return (
            f"postgresql+asyncpg://{self.username}:{self.password}"
            f"@{self.host}:{self.port}/{self.database}"
        )

@dataclass
class RedisSettings:
    """Redis ì„¤ì •"""
    host: str = "localhost"
    port: int = 6379
    database: int = 0
    password: Optional[str] = None
    
    # ì—°ê²° í’€ ì„¤ì •
    max_connections: int = 50
    socket_timeout: float = 5.0
    socket_connect_timeout: float = 5.0
    
    # í´ëŸ¬ìŠ¤í„° ì„¤ì •
    cluster_nodes: List[str] = field(default_factory=list)
    enable_cluster: bool = False
    
    # ì„¼í‹°ë„¬ ì„¤ì •
    sentinel_hosts: List[str] = field(default_factory=list)
    sentinel_service: str = "mymaster"
    enable_sentinel: bool = False
    
    def get_redis_url(self) -> str:
        """Redis URL ìƒì„±"""
        auth_part = f":{self.password}@" if self.password else ""
        return f"redis://{auth_part}{self.host}:{self.port}/{self.database}"

@dataclass
class KafkaSettings:
    """Kafka ì„¤ì •"""
    bootstrap_servers: List[str] = field(default_factory=lambda: ["localhost:9092"])
    
    # ë³´ì•ˆ ì„¤ì •
    security_protocol: str = "PLAINTEXT"
    sasl_mechanism: Optional[str] = None
    sasl_username: Optional[str] = None
    sasl_password: Optional[str] = None
    ssl_cafile: Optional[str] = None
    ssl_certfile: Optional[str] = None
    ssl_keyfile: Optional[str] = None
    
    # í”„ë¡œë“€ì„œ ì„¤ì •
    producer_acks: str = "all"
    producer_retries: int = 3
    producer_max_in_flight: int = 5
    producer_compression_type: str = "gzip"
    
    # ì»¨ìŠˆë¨¸ ì„¤ì •
    consumer_group_id: str = "newstalk-ai"
    consumer_auto_offset_reset: str = "latest"
    consumer_max_poll_records: int = 500
    
    # í† í”½ ì„¤ì •
    topics: Dict[str, str] = field(default_factory=lambda: {
        "news_raw": "news.raw",
        "news_processed": "news.processed",
        "user_interactions": "user.interactions",
        "system_events": "system.events"
    })

@dataclass
class LangGraphSettings:
    """LangGraph ì„¤ì •"""
    # PostgreSQL ì²´í¬í¬ì¸íŒ…
    postgres_url: str = ""
    checkpoint_namespace: str = "newstalk_ai"
    
    # OpenAI ì„¤ì •
    openai_api_key: str = ""
    openai_model: str = "gpt-4"
    openai_temperature: float = 0.7
    openai_max_tokens: int = 2000
    
    # Claude ì„¤ì •
    anthropic_api_key: str = ""
    anthropic_model: str = "claude-3-sonnet-20240229"
    
    # Langfuse ì¶”ì 
    langfuse_public_key: str = ""
    langfuse_secret_key: str = ""
    langfuse_host: str = "https://cloud.langfuse.com"
    
    # ì—ì´ì „íŠ¸ ì„¤ì •
    max_execution_time: int = 300  # 5ë¶„
    max_iterations: int = 10
    enable_debug: bool = False

@dataclass
class APISettings:
    """API ì„¤ì •"""
    host: str = "0.0.0.0"
    port: int = 8000
    debug: bool = False
    
    # CORS ì„¤ì •
    cors_origins: List[str] = field(default_factory=lambda: ["*"])
    cors_methods: List[str] = field(default_factory=lambda: ["*"])
    cors_headers: List[str] = field(default_factory=lambda: ["*"])
    
    # ë³´ì•ˆ ì„¤ì •
    secret_key: str = "your-secret-key-change-this"
    access_token_expire_minutes: int = 30
    refresh_token_expire_days: int = 30
    
    # ìš”ì²­ ì œí•œ
    rate_limit_requests: int = 100
    rate_limit_window: int = 60  # seconds
    
    # API í‚¤ ì„¤ì •
    api_keys: Dict[str, str] = field(default_factory=dict)

@dataclass
class MonitoringSettings:
    """ëª¨ë‹ˆí„°ë§ ì„¤ì •"""
    # Prometheus ì„¤ì •
    enable_prometheus: bool = True
    prometheus_port: int = 9090
    
    # ë¡œê¹… ì„¤ì •
    log_level: LogLevel = LogLevel.INFO
    log_format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    log_file: Optional[str] = None
    enable_json_logging: bool = False
    
    # Slack ì•Œë¦¼
    slack_webhook_url: Optional[str] = None
    slack_channel: str = "#alerts"
    enable_slack_alerts: bool = False
    
    # ë©”íŠ¸ë¦­ ì„¤ì •
    metrics_retention_days: int = 30
    enable_performance_tracking: bool = True
    
    # í—¬ìŠ¤ì²´í¬ ì„¤ì •
    health_check_interval: int = 60  # seconds
    health_check_timeout: int = 30   # seconds

@dataclass
class AISettings:
    """AI ì²˜ë¦¬ ì„¤ì •"""
    # íŒ©íŠ¸ì²´í‚¹ ì„¤ì •
    fact_check_confidence_threshold: float = 0.7
    fact_check_timeout: int = 30
    enable_fact_checking: bool = True
    
    # ìŒì„± í•©ì„± ì„¤ì •
    voice_synthesis_model: str = "azure"
    azure_speech_key: Optional[str] = None
    azure_speech_region: str = "koreacentral"
    
    # ê°ì • ë¶„ì„ ì„¤ì •
    sentiment_model: str = "huggingface"
    sentiment_threshold: float = 0.5
    
    # ê°œì¸í™” ì„¤ì •
    personalization_window_days: int = 30
    min_interactions_for_personalization: int = 10
    
    # ì„±ëŠ¥ ì„¤ì •
    ai_request_timeout: int = 60
    ai_max_concurrent_requests: int = 10
    ai_retry_attempts: int = 3

class NewsTalkSettings(BaseSettings):
    """
    NewsTalk AI í†µí•© ì„¤ì • í´ëž˜ìŠ¤
    
    í™˜ê²½ ë³€ìˆ˜, ì„¤ì • íŒŒì¼, ê¸°ë³¸ê°’ì„ í†µí•©í•˜ì—¬ ê´€ë¦¬
    """
    
    # í™˜ê²½ ì„¤ì •
    environment: Environment = Environment.DEVELOPMENT
    debug: bool = False
    version: str = "1.0.0"
    
    # ì„œë¹„ìŠ¤ë³„ ì„¤ì •
    database: DatabaseSettings = field(default_factory=DatabaseSettings)
    redis: RedisSettings = field(default_factory=RedisSettings)
    kafka: KafkaSettings = field(default_factory=KafkaSettings)
    langgraph: LangGraphSettings = field(default_factory=LangGraphSettings)
    api: APISettings = field(default_factory=APISettings)
    monitoring: MonitoringSettings = field(default_factory=MonitoringSettings)
    ai: AISettings = field(default_factory=AISettings)
    
    # ì„¤ì • ë©”íƒ€ë°ì´í„°
    config_file_path: Optional[str] = None
    config_last_updated: Optional[datetime] = None
    config_checksum: Optional[str] = None
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        env_nested_delimiter = "__"
        case_sensitive = True
        
        @classmethod
        def customise_sources(
            cls,
            init_settings: SettingsSourceCallable,
            env_settings: SettingsSourceCallable,
            file_secret_settings: SettingsSourceCallable,
        ) -> tuple[SettingsSourceCallable, ...]:
            return (
                init_settings,
                yaml_config_settings_source,
                env_settings,
                file_secret_settings,
            )
    
    def __post_init__(self):
        """ì´ˆê¸°í™” í›„ ì„¤ì • ê²€ì¦"""
        self._validate_settings()
        self._setup_logging()
        self._calculate_checksum()
    
    def _validate_settings(self):
        """ì„¤ì • ê²€ì¦"""
        try:
            # í•„ìˆ˜ ì„¤ì • ê²€ì¦
            if self.environment == Environment.PRODUCTION:
                required_settings = [
                    (self.database.password, "Database password is required in production"),
                    (self.api.secret_key != "your-secret-key-change-this", "Secret key must be changed in production"),
                    (self.langgraph.openai_api_key, "OpenAI API key is required")
                ]
                
                for condition, message in required_settings:
                    if not condition:
                        raise ValueError(f"Production validation failed: {message}")
            
            # í¬íŠ¸ ì¶©ëŒ ê²€ì¦
            used_ports = {self.api.port, self.redis.port, self.database.port}
            if self.monitoring.enable_prometheus:
                used_ports.add(self.monitoring.prometheus_port)
            
            if len(used_ports) != len({self.api.port, self.redis.port, self.database.port, self.monitoring.prometheus_port}):
                logger.warning("Port conflicts detected in configuration")
            
            # URL í˜•ì‹ ê²€ì¦
            if self.redis.host and not self._is_valid_host(self.redis.host):
                raise ValueError(f"Invalid Redis host: {self.redis.host}")
            
            if self.database.host and not self._is_valid_host(self.database.host):
                raise ValueError(f"Invalid database host: {self.database.host}")
            
            logger.info("Configuration validation completed successfully")
            
        except Exception as e:
            logger.error(f"Configuration validation failed: {e}")
            raise
    
    def _is_valid_host(self, host: str) -> bool:
        """í˜¸ìŠ¤íŠ¸ëª… ìœ íš¨ì„± ê²€ì¦"""
        import re
        # IPv4, IPv6, ë„ë©”ì¸ëª… ê²€ì¦
        ipv4_pattern = r'^(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$'
        domain_pattern = r'^(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)*[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?$'
        
        return (
            host == "localhost" or
            re.match(ipv4_pattern, host) or
            re.match(domain_pattern, host)
        )
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        log_level = getattr(logging, self.monitoring.log_level.value)
        
        # ê¸°ë³¸ ë¡œê±° ì„¤ì •
        logging.basicConfig(
            level=log_level,
            format=self.monitoring.log_format,
            filename=self.monitoring.log_file
        )
        
        # JSON ë¡œê¹… ì„¤ì •
        if self.monitoring.enable_json_logging:
            try:
                import pythonjsonlogger.jsonlogger
                json_handler = logging.StreamHandler()
                formatter = pythonjsonlogger.jsonlogger.JsonFormatter()
                json_handler.setFormatter(formatter)
                
                root_logger = logging.getLogger()
                root_logger.addHandler(json_handler)
                
            except ImportError:
                logger.warning("pythonjsonlogger not installed, falling back to standard logging")
    
    def _calculate_checksum(self):
        """ì„¤ì • ì²´í¬ì„¬ ê³„ì‚°"""
        try:
            config_str = self.json(sort_keys=True)
            self.config_checksum = hashlib.sha256(config_str.encode()).hexdigest()
            self.config_last_updated = datetime.utcnow()
        except Exception as e:
            logger.error(f"Failed to calculate config checksum: {e}")
    
    def get_database_url(self, for_replica: bool = False) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ URL ë°˜í™˜"""
        return self.database.get_database_url(for_replica)
    
    def get_redis_url(self) -> str:
        """Redis URL ë°˜í™˜"""
        return self.redis.get_redis_url()
    
    def is_production(self) -> bool:
        """í”„ë¡œë•ì…˜ í™˜ê²½ ì—¬ë¶€"""
        return self.environment == Environment.PRODUCTION
    
    def is_development(self) -> bool:
        """ê°œë°œ í™˜ê²½ ì—¬ë¶€"""
        return self.environment == Environment.DEVELOPMENT
    
    def get_kafka_config(self) -> Dict[str, Any]:
        """Kafka í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ë°˜í™˜"""
        config = {
            "bootstrap_servers": self.kafka.bootstrap_servers,
            "security_protocol": self.kafka.security_protocol,
        }
        
        if self.kafka.sasl_mechanism:
            config.update({
                "sasl_mechanism": self.kafka.sasl_mechanism,
                "sasl_plain_username": self.kafka.sasl_username,
                "sasl_plain_password": self.kafka.sasl_password,
            })
        
        if self.kafka.ssl_cafile:
            config.update({
                "ssl_cafile": self.kafka.ssl_cafile,
                "ssl_certfile": self.kafka.ssl_certfile,
                "ssl_keyfile": self.kafka.ssl_keyfile,
            })
        
        return config
    
    def export_config(self, include_secrets: bool = False) -> Dict[str, Any]:
        """ì„¤ì •ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë‚´ë³´ë‚´ê¸°"""
        config_dict = self.dict()
        
        if not include_secrets:
            # ë¯¼ê°í•œ ì •ë³´ ë§ˆìŠ¤í‚¹
            sensitive_fields = [
                "database.password",
                "redis.password", 
                "kafka.sasl_password",
                "langgraph.openai_api_key",
                "langgraph.anthropic_api_key",
                "langgraph.langfuse_secret_key",
                "api.secret_key",
                "api.api_keys",
                "monitoring.slack_webhook_url",
                "ai.azure_speech_key"
            ]
            
            for field in sensitive_fields:
                keys = field.split(".")
                current = config_dict
                for key in keys[:-1]:
                    if key in current:
                        current = current[key]
                    else:
                        break
                else:
                    if keys[-1] in current and current[keys[-1]]:
                        current[keys[-1]] = "***MASKED***"
        
        return config_dict
    
    async def reload_from_file(self, config_path: str = None):
        """íŒŒì¼ì—ì„œ ì„¤ì • ë‹¤ì‹œ ë¡œë“œ"""
        try:
            if config_path:
                self.config_file_path = config_path
            
            if self.config_file_path and Path(self.config_file_path).exists():
                # íŒŒì¼ ë¡œë“œ ë° ì„¤ì • ì—…ë°ì´íŠ¸
                new_settings = load_config_from_file(self.config_file_path)
                
                # ì„¤ì • ë³‘í•©
                for key, value in new_settings.items():
                    if hasattr(self, key):
                        setattr(self, key, value)
                
                # ê²€ì¦ ë° ì²´í¬ì„¬ ìž¬ê³„ì‚°
                self._validate_settings()
                self._calculate_checksum()
                
                logger.info(f"Configuration reloaded from {self.config_file_path}")
            
        except Exception as e:
            logger.error(f"Failed to reload configuration: {e}")
            raise
    
    def has_changed(self, other_checksum: str) -> bool:
        """ì„¤ì • ë³€ê²½ ì—¬ë¶€ í™•ì¸"""
        return self.config_checksum != other_checksum

def yaml_config_settings_source(settings: BaseSettings) -> Dict[str, Any]:
    """YAML ì„¤ì • íŒŒì¼ ì†ŒìŠ¤"""
    config_data = {}
    
    # í™˜ê²½ë³„ ì„¤ì • íŒŒì¼ íƒìƒ‰
    env = os.getenv("ENVIRONMENT", "development").lower()
    config_files = [
        f"config.{env}.yaml",
        f"config.{env}.yml", 
        "config.yaml",
        "config.yml"
    ]
    
    for config_file in config_files:
        config_path = Path(config_file)
        if config_path.exists():
            try:
                config_data = load_config_from_file(str(config_path))
                logger.info(f"Loaded configuration from {config_path}")
                break
            except Exception as e:
                logger.warning(f"Failed to load {config_path}: {e}")
                continue
    
    return config_data

def load_config_from_file(file_path: str) -> Dict[str, Any]:
    """íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ"""
    config_path = Path(file_path)
    
    if not config_path.exists():
        logger.warning(f"Config file not found: {file_path}")
        return {}
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            if config_path.suffix.lower() in ['.yaml', '.yml']:
                return yaml.safe_load(f) or {}
            elif config_path.suffix.lower() == '.json':
                return json.load(f) or {}
            else:
                logger.warning(f"Unsupported config file format: {config_path.suffix}")
                return {}
                
    except Exception as e:
        logger.error(f"Failed to load config from {file_path}: {e}")
        raise

class ConfigManager:
    """
    ì„¤ì • ê´€ë¦¬ìž
    
    ë™ì  ì„¤ì • ì—…ë°ì´íŠ¸, ë¶„ì‚° ì„¤ì • ê´€ë¦¬, ì„¤ì • ê°ì‚¬ ë“±ì„ ë‹´ë‹¹
    """
    
    def __init__(self, settings: NewsTalkSettings):
        self.settings = settings
        self._redis_client: Optional[redis.Redis] = None
        self._config_watchers: List[Callable] = []
        self._last_update_check = datetime.utcnow()
        
    async def initialize(self):
        """ì„¤ì • ê´€ë¦¬ìž ì´ˆê¸°í™”"""
        try:
            # Redis ì—°ê²° (ë¶„ì‚° ì„¤ì •ìš©)
            if self.settings.redis.host:
                self._redis_client = redis.from_url(
                    self.settings.get_redis_url(),
                    encoding="utf-8",
                    decode_responses=True
                )
                await self._redis_client.ping()
                logger.info("Redis connection established for configuration management")
                
        except Exception as e:
            logger.warning(f"Failed to initialize Redis for config management: {e}")
    
    async def watch_config_changes(self, callback: Callable):
        """ì„¤ì • ë³€ê²½ ê°ì‹œ ì½œë°± ë“±ë¡"""
        self._config_watchers.append(callback)
    
    async def update_config(self, key: str, value: Any, persist: bool = True):
        """ë™ì  ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            # ì„¤ì • ì—…ë°ì´íŠ¸
            keys = key.split(".")
            current = self.settings
            
            for k in keys[:-1]:
                current = getattr(current, k)
            
            setattr(current, keys[-1], value)
            
            # Redisì— ì €ìž¥ (ë¶„ì‚° í™˜ê²½ìš©)
            if persist and self._redis_client:
                await self._redis_client.set(
                    f"config:{key}",
                    json.dumps(value, default=str),
                    ex=3600  # 1ì‹œê°„ TTL
                )
            
            # ì½œë°± ì‹¤í–‰
            for callback in self._config_watchers:
                try:
                    await callback(key, value)
                except Exception as e:
                    logger.error(f"Config watcher callback failed: {e}")
            
            logger.info(f"Configuration updated: {key} = {value}")
            
        except Exception as e:
            logger.error(f"Failed to update configuration {key}: {e}")
            raise
    
    async def get_distributed_config(self, key: str) -> Optional[Any]:
        """ë¶„ì‚° ì„¤ì • ì¡°íšŒ"""
        if not self._redis_client:
            return None
        
        try:
            value = await self._redis_client.get(f"config:{key}")
            if value:
                return json.loads(value)
        except Exception as e:
            logger.error(f"Failed to get distributed config {key}: {e}")
        
        return None
    
    async def sync_distributed_config(self):
        """ë¶„ì‚° ì„¤ì • ë™ê¸°í™”"""
        if not self._redis_client:
            return
        
        try:
            # Redisì—ì„œ ëª¨ë“  ì„¤ì • í‚¤ ì¡°íšŒ
            keys = await self._redis_client.keys("config:*")
            
            for key in keys:
                config_key = key.replace("config:", "")
                value = await self.get_distributed_config(config_key)
                
                if value is not None:
                    await self.update_config(config_key, value, persist=False)
            
        except Exception as e:
            logger.error(f"Failed to sync distributed config: {e}")
    
    def get_config_audit_log(self) -> List[Dict[str, Any]]:
        """ì„¤ì • ë³€ê²½ ê°ì‚¬ ë¡œê·¸ ë°˜í™˜"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë‚˜ íŒŒì¼ì—ì„œ ë¡œë“œ
        return [
            {
                "timestamp": datetime.utcnow().isoformat(),
                "config_key": "example.key",
                "old_value": "old_value",
                "new_value": "new_value",
                "user": "system",
                "environment": self.settings.environment.value
            }
        ]

# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
_settings: Optional[NewsTalkSettings] = None
_config_manager: Optional[ConfigManager] = None

def get_settings() -> NewsTalkSettings:
    """ì„¤ì • ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _settings
    if _settings is None:
        try:
            _settings = NewsTalkSettings()
            logger.info(f"Settings loaded for environment: {_settings.environment.value}")
        except Exception as e:
            logger.error(f"Failed to load settings: {e}")
            # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í´ë°±
            _settings = NewsTalkSettings(environment=Environment.DEVELOPMENT)
    
    return _settings

async def get_config_manager() -> ConfigManager:
    """ì„¤ì • ê´€ë¦¬ìž ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _config_manager
    if _config_manager is None:
        settings = get_settings()
        _config_manager = ConfigManager(settings)
        await _config_manager.initialize()
    
    return _config_manager

def reload_settings(config_path: str = None):
    """ì„¤ì • ë‹¤ì‹œ ë¡œë“œ"""
    global _settings, _config_manager
    _settings = None
    _config_manager = None
    
    if config_path:
        os.environ["CONFIG_FILE_PATH"] = config_path
    
    return get_settings()

# íŽ¸ì˜ í•¨ìˆ˜ë“¤
def get_database_url(for_replica: bool = False) -> str:
    """ë°ì´í„°ë² ì´ìŠ¤ URL ë°˜í™˜"""
    return get_settings().get_database_url(for_replica)

def get_redis_url() -> str:
    """Redis URL ë°˜í™˜"""
    return get_settings().get_redis_url()

def is_production() -> bool:
    """í”„ë¡œë•ì…˜ í™˜ê²½ ì—¬ë¶€"""
    return get_settings().is_production()

def is_development() -> bool:
    """ê°œë°œ í™˜ê²½ ì—¬ë¶€"""
    return get_settings().is_development()

def get_log_level() -> str:
    """ë¡œê·¸ ë ˆë²¨ ë°˜í™˜"""
    return get_settings().monitoring.log_level.value