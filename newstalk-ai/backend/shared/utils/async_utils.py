"""
ğŸ¯ NewsTalk AI ë¹„ë™ê¸° ì²˜ë¦¬ í‘œì¤€í™” ì‹œìŠ¤í…œ
=========================================

Airflow í˜¸í™˜ì„±ê³¼ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œìŠ¤í…œ:
- Airflow DAGì™€ asyncio ì´ë²¤íŠ¸ ë£¨í”„ í˜¸í™˜ì„± ë³´ì¥
- ë°±í”„ë ˆì…” ì œì–´ì™€ ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •
- ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
"""

import asyncio
import functools
import logging
import time
import weakref
from concurrent.futures import ThreadPoolExecutor
from contextlib import asynccontextmanager
from dataclasses import dataclass
from enum import Enum
from typing import (
    Any,
    Awaitable,
    Callable,
    List,
    Optional,
    Tuple,
    TypeVar,
    Union,
)


logger = logging.getLogger(__name__)

T = TypeVar("T")
F = TypeVar("F", bound=Callable[..., Any])


class ProcessingMode(Enum):
    """ì²˜ë¦¬ ëª¨ë“œ"""

    SEQUENTIAL = "sequential"  # ìˆœì°¨ ì²˜ë¦¬
    PARALLEL = "parallel"  # ë³‘ë ¬ ì²˜ë¦¬
    BATCH = "batch"  # ë°°ì¹˜ ì²˜ë¦¬
    STREAMING = "streaming"  # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬


@dataclass
class AsyncConfig:
    """ë¹„ë™ê¸° ì²˜ë¦¬ ì„¤ì •"""

    max_concurrency: int = 10
    batch_size: int = 50
    timeout_seconds: float = 30.0
    retry_attempts: int = 3
    backoff_factor: float = 1.5
    backoff_max: float = 60.0
    enable_backpressure: bool = True
    memory_limit_mb: float = 1024.0
    processing_mode: ProcessingMode = ProcessingMode.PARALLEL


@dataclass
class ProcessingStats:
    """ì²˜ë¦¬ í†µê³„"""

    total_items: int = 0
    processed_items: int = 0
    failed_items: int = 0
    processing_time: float = 0.0
    average_time_per_item: float = 0.0
    peak_memory_mb: float = 0.0
    retry_count: int = 0
    last_error: Optional[str] = None


class AsyncProcessorPool:
    """
    ë¹„ë™ê¸° í”„ë¡œì„¸ì„œ í’€

    ì£¼ìš” ê¸°ëŠ¥:
    - ë™ì  ìŠ¤ì¼€ì¼ë§ (ì²˜ë¦¬ëŸ‰ì— ë”°ë¥¸ ìë™ ì¡°ì •)
    - ë°±í”„ë ˆì…” ì œì–´ (ë©”ëª¨ë¦¬ ì••ë°• ì‹œ ì²˜ë¦¬ ì†ë„ ì¡°ì ˆ)
    - í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§ (ì‘ë‹µ ì‹œê°„, ì—ëŸ¬ìœ¨ ì¶”ì )
    - ê·¸ë ˆì´ìŠ¤í’€ ì…§ë‹¤ìš´
    """

    def __init__(self, config: AsyncConfig = None):
        self.config = config or AsyncConfig()
        self.semaphore = asyncio.Semaphore(self.config.max_concurrency)
        self.stats = ProcessingStats()
        self.active_tasks: weakref.WeakSet = weakref.WeakSet()
        self.is_running = False
        self._shutdown_event = asyncio.Event()

        # ë°±í”„ë ˆì…” ì œì–´
        self._memory_monitor_task: Optional[asyncio.Task] = None
        self._current_memory_mb = 0.0
        self._backpressure_active = False

        logger.info(
            f"AsyncProcessorPool initialized with max_concurrency={self.config.max_concurrency}"
        )

    async def process_items(
        self,
        items: List[T],
        processor_func: Callable[[T], Awaitable[Any]],
        progress_callback: Optional[Callable[[int, int], None]] = None,
    ) -> List[Union[Any, Exception]]:
        """
        ì•„ì´í…œë“¤ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬

        Args:
            items: ì²˜ë¦¬í•  ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
            processor_func: ì²˜ë¦¬ í•¨ìˆ˜
            progress_callback: ì§„í–‰ë¥  ì½œë°±

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ì„±ê³µ/ì‹¤íŒ¨ í˜¼ì¬)
        """
        if not items:
            return []

        self.stats.total_items = len(items)
        self.stats.processed_items = 0
        self.stats.failed_items = 0
        start_time = time.time()

        try:
            self.is_running = True
            await self._start_memory_monitor()

            # ì²˜ë¦¬ ëª¨ë“œì— ë”°ë¥¸ ë¶„ê¸°
            if self.config.processing_mode == ProcessingMode.SEQUENTIAL:
                results = await self._process_sequential(items, processor_func, progress_callback)
            elif self.config.processing_mode == ProcessingMode.BATCH:
                results = await self._process_batch(items, processor_func, progress_callback)
            elif self.config.processing_mode == ProcessingMode.STREAMING:
                results = await self._process_streaming(items, processor_func, progress_callback)
            else:  # PARALLEL
                results = await self._process_parallel(items, processor_func, progress_callback)

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats.processing_time = time.time() - start_time
            if self.stats.processed_items > 0:
                self.stats.average_time_per_item = (
                    self.stats.processing_time / self.stats.processed_items
                )

            return results

        except Exception as e:
            self.stats.last_error = str(e)
            logger.error(f"Processing failed: {e}")
            raise
        finally:
            self.is_running = False
            await self._stop_memory_monitor()

    async def _process_parallel(
        self,
        items: List[T],
        processor_func: Callable[[T], Awaitable[Any]],
        progress_callback: Optional[Callable[[int, int], None]],
    ) -> List[Union[Any, Exception]]:
        """ë³‘ë ¬ ì²˜ë¦¬"""

        async def process_single_item(item: T, index: int) -> Tuple[int, Union[Any, Exception]]:
            async with self.semaphore:
                # ë°±í”„ë ˆì…” ëŒ€ê¸°
                while self._backpressure_active:
                    await asyncio.sleep(0.1)

                try:
                    result = await asyncio.wait_for(
                        processor_func(item), timeout=self.config.timeout_seconds
                    )
                    self.stats.processed_items += 1

                    if progress_callback:
                        progress_callback(self.stats.processed_items, self.stats.total_items)

                    return index, result

                except Exception as e:
                    self.stats.failed_items += 1
                    return index, e

        # ëª¨ë“  ì•„ì´í…œì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
        tasks = [asyncio.create_task(process_single_item(item, i)) for i, item in enumerate(items)]

        # íƒœìŠ¤í¬ ì•½í•œ ì°¸ì¡° ì €ì¥ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
        for task in tasks:
            self.active_tasks.add(task)

        # ì™„ë£Œ ëŒ€ê¸°
        completed_results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ë¥¼ ì›ë˜ ìˆœì„œë¡œ ì •ë ¬
        results = [None] * len(items)
        for result in completed_results:
            if isinstance(result, tuple) and len(result) == 2:
                index, value = result
                results[index] = value

        return results

    async def _process_batch(
        self,
        items: List[T],
        processor_func: Callable[[T], Awaitable[Any]],
        progress_callback: Optional[Callable[[int, int], None]],
    ) -> List[Union[Any, Exception]]:
        """ë°°ì¹˜ ì²˜ë¦¬"""
        results = []

        for i in range(0, len(items), self.config.batch_size):
            batch = items[i : i + self.config.batch_size]

            # ë°±í”„ë ˆì…” ëŒ€ê¸°
            while self._backpressure_active:
                await asyncio.sleep(0.1)

            # ë°°ì¹˜ ë‚´ ë³‘ë ¬ ì²˜ë¦¬
            batch_tasks = [asyncio.create_task(processor_func(item)) for item in batch]

            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
            results.extend(batch_results)

            # í†µê³„ ì—…ë°ì´íŠ¸
            successful = sum(1 for r in batch_results if not isinstance(r, Exception))
            failed = len(batch_results) - successful

            self.stats.processed_items += successful
            self.stats.failed_items += failed

            if progress_callback:
                progress_callback(self.stats.processed_items, self.stats.total_items)

            logger.debug(
                f"Batch {i//self.config.batch_size + 1} completed: {successful}/{len(batch)} successful"
            )

        return results

    async def _process_sequential(
        self,
        items: List[T],
        processor_func: Callable[[T], Awaitable[Any]],
        progress_callback: Optional[Callable[[int, int], None]],
    ) -> List[Union[Any, Exception]]:
        """ìˆœì°¨ ì²˜ë¦¬"""
        results = []

        for item in items:
            try:
                result = await asyncio.wait_for(
                    processor_func(item), timeout=self.config.timeout_seconds
                )
                results.append(result)
                self.stats.processed_items += 1

            except Exception as e:
                results.append(e)
                self.stats.failed_items += 1

            if progress_callback:
                progress_callback(self.stats.processed_items, self.stats.total_items)

        return results

    async def _process_streaming(
        self,
        items: List[T],
        processor_func: Callable[[T], Awaitable[Any]],
        progress_callback: Optional[Callable[[int, int], None]],
    ) -> List[Union[Any, Exception]]:
        """ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ (ê²°ê³¼ë¥¼ ì¦‰ì‹œ ìƒì„±)"""
        # ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ëŠ” ë³„ë„ ì œë„ˆë ˆì´í„°ë¡œ êµ¬í˜„í•˜ëŠ” ê²ƒì´ ì ì ˆ
        # ì—¬ê¸°ì„œëŠ” ë°°ì¹˜ ì²˜ë¦¬ì™€ ìœ ì‚¬í•˜ê²Œ êµ¬í˜„
        return await self._process_batch(items, processor_func, progress_callback)

    async def _start_memory_monitor(self):
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.config.enable_backpressure:
            self._memory_monitor_task = asyncio.create_task(self._monitor_memory())

    async def _stop_memory_monitor(self):
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨"""
        if self._memory_monitor_task:
            self._memory_monitor_task.cancel()
            try:
                await self._memory_monitor_task
            except asyncio.CancelledError:
                pass

    async def _monitor_memory(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§"""
        import psutil

        while self.is_running:
            try:
                # í˜„ì¬ í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                process = psutil.Process()
                memory_info = process.memory_info()
                self._current_memory_mb = memory_info.rss / (1024 * 1024)

                # ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
                if self._current_memory_mb > self.stats.peak_memory_mb:
                    self.stats.peak_memory_mb = self._current_memory_mb

                # ë°±í”„ë ˆì…” ì œì–´
                memory_threshold = self.config.memory_limit_mb * 0.8  # 80% ì„ê³„ì¹˜
                if self._current_memory_mb > memory_threshold:
                    if not self._backpressure_active:
                        self._backpressure_active = True
                        logger.warning(
                            f"Backpressure activated: {self._current_memory_mb:.1f}MB > {memory_threshold:.1f}MB"
                        )
                else:
                    if self._backpressure_active:
                        self._backpressure_active = False
                        logger.info("Backpressure deactivated")

                await asyncio.sleep(1)  # 1ì´ˆë§ˆë‹¤ ì²´í¬

            except Exception as e:
                logger.error(f"Memory monitoring error: {e}")
                await asyncio.sleep(5)  # ì—ëŸ¬ ì‹œ 5ì´ˆ ëŒ€ê¸°


class RetryManager:
    """
    ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ê´€ë¦¬ì
    """

    def __init__(self, config: AsyncConfig = None):
        self.config = config or AsyncConfig()
        logger.info(f"RetryManager initialized with {self.config.retry_attempts} max attempts")

    async def execute_with_retry(self, func: Callable[..., Awaitable[T]], *args, **kwargs) -> T:
        """ì¬ì‹œë„ ë¡œì§ìœ¼ë¡œ í•¨ìˆ˜ ì‹¤í–‰"""
        last_exception = None

        for attempt in range(self.config.retry_attempts):
            try:
                return await func(*args, **kwargs)

            except Exception as e:
                last_exception = e

                if attempt < self.config.retry_attempts - 1:
                    # ì§€ìˆ˜ ë°±ì˜¤í”„ ê³„ì‚°
                    delay = min(self.config.backoff_factor**attempt, self.config.backoff_max)

                    logger.warning(
                        f"Attempt {attempt + 1} failed: {e}. " f"Retrying in {delay:.1f} seconds..."
                    )

                    await asyncio.sleep(delay)
                else:
                    logger.error(f"All {self.config.retry_attempts} attempts failed")

        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        raise last_exception


def airflow_async_task(timeout: float = 300.0, retries: int = 3, pool_size: int = 10):
    """
    Airflow í˜¸í™˜ ë¹„ë™ê¸° íƒœìŠ¤í¬ ë°ì½”ë ˆì´í„°

    Airflow DAGì—ì„œ ì•ˆì „í•˜ê²Œ asyncio ì½”ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ ì§€ì›
    """

    def decorator(func: Callable[..., Awaitable[T]]) -> Callable[..., T]:
        @functools.wraps(func)
        def wrapper(*args, **kwargs) -> T:
            # Airflow ì»¨í…ìŠ¤íŠ¸ì—ì„œëŠ” ìƒˆë¡œìš´ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±
            try:
                # ê¸°ì¡´ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
                asyncio.get_running_loop()
                logger.warning("Running loop detected in Airflow context")

                # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
                with ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(
                        _run_async_in_thread, func, args, kwargs, timeout, retries
                    )
                    return future.result()

            except RuntimeError:
                # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì—†ëŠ” ê²½ìš° ì§ì ‘ ì‹¤í–‰
                return asyncio.run(
                    _run_with_timeout_and_retry(func, args, kwargs, timeout, retries)
                )

        return wrapper

    return decorator


def _run_async_in_thread(func, args, kwargs, timeout, retries):
    """ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰"""
    return asyncio.run(_run_with_timeout_and_retry(func, args, kwargs, timeout, retries))


async def _run_with_timeout_and_retry(func, args, kwargs, timeout, retries):
    """íƒ€ì„ì•„ì›ƒê³¼ ì¬ì‹œë„ê°€ í¬í•¨ëœ ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰"""
    retry_manager = RetryManager(AsyncConfig(retry_attempts=retries, timeout_seconds=timeout))

    return await retry_manager.execute_with_retry(func, *args, **kwargs)


@asynccontextmanager
async def async_resource_pool(
    create_resource: Callable[[], Awaitable[T]],
    close_resource: Callable[[T], Awaitable[None]],
    pool_size: int = 10,
    max_lifetime: float = 3600.0,
):
    """
    ë¹„ë™ê¸° ë¦¬ì†ŒìŠ¤ í’€ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €

    Args:
        create_resource: ë¦¬ì†ŒìŠ¤ ìƒì„± í•¨ìˆ˜
        close_resource: ë¦¬ì†ŒìŠ¤ í•´ì œ í•¨ìˆ˜
        pool_size: í’€ í¬ê¸°
        max_lifetime: ë¦¬ì†ŒìŠ¤ ìµœëŒ€ ìˆ˜ëª… (ì´ˆ)
    """
    pool = []
    created_times = []

    try:
        # ì´ˆê¸° ë¦¬ì†ŒìŠ¤ ìƒì„±
        logger.info(f"Creating resource pool with size {pool_size}")

        for _ in range(pool_size):
            resource = await create_resource()
            pool.append(resource)
            created_times.append(time.time())

        yield ResourcePool(pool, created_times, create_resource, close_resource, max_lifetime)

    finally:
        # ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        logger.info("Cleaning up resource pool")

        for resource in pool:
            try:
                await close_resource(resource)
            except Exception as e:
                logger.error(f"Error closing resource: {e}")


class ResourcePool:
    """ë¦¬ì†ŒìŠ¤ í’€ ë˜í¼"""

    def __init__(self, pool, created_times, create_func, close_func, max_lifetime):
        self.pool = pool
        self.created_times = created_times
        self.create_func = create_func
        self.close_func = close_func
        self.max_lifetime = max_lifetime
        self.lock = asyncio.Lock()

    async def acquire(self) -> T:
        """ë¦¬ì†ŒìŠ¤ íšë“"""
        async with self.lock:
            current_time = time.time()

            # ìˆ˜ëª…ì´ ë‹¤í•œ ë¦¬ì†ŒìŠ¤ êµì²´
            for i, created_time in enumerate(self.created_times):
                if current_time - created_time > self.max_lifetime:
                    old_resource = self.pool[i]
                    try:
                        await self.close_func(old_resource)
                    except Exception as e:
                        logger.error(f"Error closing expired resource: {e}")

                    # ìƒˆ ë¦¬ì†ŒìŠ¤ ìƒì„±
                    new_resource = await self.create_func()
                    self.pool[i] = new_resource
                    self.created_times[i] = current_time

            # ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤ ë°˜í™˜ (ë¼ìš´ë“œ ë¡œë¹ˆ)
            return self.pool[0]  # ê°„ë‹¨í•œ êµ¬í˜„


def batch_processor(batch_size: int = 100, timeout: float = 30.0, max_concurrency: int = 10):
    """ë°°ì¹˜ ì²˜ë¦¬ ë°ì½”ë ˆì´í„°"""

    def decorator(func: Callable[[List[T]], Awaitable[List[Any]]]):
        @functools.wraps(func)
        async def wrapper(items: List[T]) -> List[Any]:
            if not items:
                return []

            config = AsyncConfig(
                batch_size=batch_size,
                timeout_seconds=timeout,
                max_concurrency=max_concurrency,
                processing_mode=ProcessingMode.BATCH,
            )

            pool = AsyncProcessorPool(config)

            # ë‹¨ì¼ ì•„ì´í…œ í”„ë¡œì„¸ì„œ ë˜í¼
            async def single_item_processor(item: T) -> Any:
                # ë°°ì¹˜ í¬ê¸°ë§Œí¼ ëª¨ì•„ì„œ ì²˜ë¦¬
                return await func([item])

            results = await pool.process_items(items, single_item_processor)

            # ë°°ì¹˜ ê²°ê³¼ë¥¼ í‰íƒ„í™”
            flattened_results = []
            for result in results:
                if isinstance(result, list):
                    flattened_results.extend(result)
                else:
                    flattened_results.append(result)

            return flattened_results

        return wrapper

    return decorator


async def safe_gather(*coros, return_exceptions: bool = True) -> List[Union[Any, Exception]]:
    """
    ì•ˆì „í•œ gather êµ¬í˜„ - ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
    """
    tasks = [asyncio.create_task(coro) for coro in coros]

    try:
        return await asyncio.gather(*tasks, return_exceptions=return_exceptions)
    finally:
        # ì™„ë£Œë˜ì§€ ì•Šì€ íƒœìŠ¤í¬ ì •ë¦¬
        for task in tasks:
            if not task.done():
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass


# í¸ì˜ í•¨ìˆ˜ë“¤
async def run_in_thread_pool(func: Callable[..., T], *args, **kwargs) -> T:
    """ìŠ¤ë ˆë“œ í’€ì—ì„œ ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰"""
    loop = asyncio.get_running_loop()
    return await loop.run_in_executor(None, functools.partial(func, **kwargs), *args)


def sync_to_async(func: Callable[..., T]) -> Callable[..., Awaitable[T]]:
    """ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ ë³€í™˜"""

    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        return await run_in_thread_pool(func, *args, **kwargs)

    return wrapper


def async_to_sync(func: Callable[..., Awaitable[T]]) -> Callable[..., T]:
    """ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸° í•¨ìˆ˜ë¡œ ë³€í™˜ (Airflow í˜¸í™˜)"""

    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        try:
            asyncio.get_running_loop()
            # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            with ThreadPoolExecutor() as executor:
                future = executor.submit(asyncio.run, func(*args, **kwargs))
                return future.result()
        except RuntimeError:
            # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ì§ì ‘ ì‹¤í–‰
            return asyncio.run(func(*args, **kwargs))

    return wrapper
