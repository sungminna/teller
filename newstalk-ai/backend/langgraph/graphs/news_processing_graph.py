"""
ğŸ¯ NewsTalk AI í†µí•© ì›Œí¬í”Œë¡œìš° - LangGraph StateGraph (Stage 3)
3ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ ìˆœì°¨ ì‹¤í–‰: ë‰´ìŠ¤ë¶„ì„(+íŒ©íŠ¸ì²´í‚¹) â†’ ê°œì¸í™”(+ìŠ¤í† ë¦¬í…”ë§) â†’ ìŒì„±í•©ì„±
95% íŒ©íŠ¸ì²´í‚¹ ì •í™•ë„, 4.5/5.0 ê°œì¸í™” ë§Œì¡±ë„, í”„ë¡œ ì„±ìš° ìˆ˜ì¤€ ìŒì„± í’ˆì§ˆ
"""
import asyncio
import logging
from datetime import datetime
from typing import Dict, List, Optional, Literal
from uuid import uuid4

from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.postgres import PostgresCheckpointer
from langgraph.pregel import Pregel
from langfuse import Langfuse

from ..state.news_state import NewsState, ProcessingStage
from ..agents.analysis_agent import AnalysisAgent
from ..agents.personalization_agent import PersonalizationAgent
from ..agents.voice_synthesis_agent import VoiceSynthesisAgent
from ...shared.config.settings import settings

logger = logging.getLogger(__name__)

class NewsProcessingGraph:
    """
    ğŸ¯ NewsTalk AI ë©”ì¸ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ (Stage 3)
    - 3ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ ìˆœì°¨ ì‹¤í–‰
    - News Analysis Agent: 95% íŒ©íŠ¸ì²´í‚¹ ì •í™•ë„ ëª©í‘œ
    - Personalization Agent: 4.5/5.0 ê°œì¸í™” ë§Œì¡±ë„ + ìŠ¤í† ë¦¬í…”ë§
    - Voice Synthesis Agent: í”„ë¡œ ì„±ìš° ìˆ˜ì¤€ ìŒì„± í’ˆì§ˆ
    - PostgreSQL ì²´í¬í¬ì¸íŒ…ìœ¼ë¡œ ì•ˆì •ì„± ë³´ì¥
    - Human-in-the-loop ê²€í†  ì§€ì›
    """
    
    def __init__(self):
        # ğŸ¯ 3ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (Stage 3)
        self.analysis_agent = AnalysisAgent()                    # ë‰´ìŠ¤ë¶„ì„ + íŒ©íŠ¸ì²´í‚¹ í†µí•©
        self.personalization_agent = PersonalizationAgent()     # ê°œì¸í™” + ìŠ¤í† ë¦¬í…”ë§ í†µí•©  
        self.voice_synthesis_agent = VoiceSynthesisAgent()       # ë‹¤ì¤‘ ìºë¦­í„° ìŒì„±í•©ì„±
        
        # PostgreSQL ì²´í¬í¬ì¸í„° ì„¤ì •
        self.checkpointer = PostgresCheckpointer(
            connection_string=settings.ai.postgres_checkpoint_url,
            serde_kwargs={"allow_dangerous_deserialization": True}
        )
        
        # Langfuse ì¶”ì 
        self.langfuse = Langfuse(
            public_key=settings.ai.langfuse_public_key,
            secret_key=settings.ai.langfuse_secret_key,
            host=settings.ai.langfuse_host
        )
        
        # StateGraph êµ¬ì„±
        self.graph = self._build_graph()
        
        logger.info("ğŸ¯ NewsTalk AI Processing Graph initialized with 3 specialized agents (Stage 3)")
    
    def _build_graph(self) -> Pregel:
        """LangGraph StateGraph êµ¬ì¶•"""
        
        # StateGraph ìƒì„±
        workflow = StateGraph(NewsState)
        
        # ğŸ¯ ë…¸ë“œ ì¶”ê°€ (3ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ + í’ˆì§ˆ ê²€ì¦) - Stage 3
        workflow.add_node("news_analysis", self._analysis_node)              # ë‰´ìŠ¤ë¶„ì„ + íŒ©íŠ¸ì²´í‚¹
        workflow.add_node("personalization", self._personalization_node)    # ê°œì¸í™” + ìŠ¤í† ë¦¬í…”ë§
        workflow.add_node("voice_synthesis", self._voice_synthesis_node)     # ìŒì„±í•©ì„±
        workflow.add_node("quality_validation", self._quality_validation_node)
        workflow.add_node("human_review", self._human_review_node)
        workflow.add_node("completion", self._completion_node)
        
        # ì›Œí¬í”Œë¡œìš° ì‹œì‘ì 
        workflow.set_entry_point("news_analysis")
        
        # ğŸ¯ ì—£ì§€ ì •ì˜ (3ê°œ ì—ì´ì „íŠ¸ ìˆœì°¨ ì‹¤í–‰) - Stage 3
        workflow.add_conditional_edges(
            "news_analysis",
            self._should_proceed_after_analysis,
            {
                "continue": "personalization",
                "quality_check": "quality_validation",
                "human_review": "human_review",
                "end": END
            }
        )
        
        workflow.add_conditional_edges(
            "personalization", 
            self._should_proceed_after_personalization,
            {
                "continue": "voice_synthesis",
                "quality_check": "quality_validation",
                "human_review": "human_review",
                "end": END
            }
        )
        
        workflow.add_conditional_edges(
            "voice_synthesis",
            self._should_proceed_after_voice_synthesis,
            {
                "continue": "completion",
                "quality_check": "quality_validation",
                "human_review": "human_review", 
                "end": END
            }
        )
        
        # í’ˆì§ˆ ê²€ì¦ í›„ ë¼ìš°íŒ…
        workflow.add_conditional_edges(
            "quality_validation",
            self._route_after_quality_check,
            {
                "retry_analysis": "news_analysis",
                "retry_personalization": "personalization",
                "retry_voice": "voice_synthesis",
                "human_review": "human_review",
                "continue": "completion",
                "end": END
            }
        )
        
        # íœ´ë¨¼ ë¦¬ë·° í›„ ë¼ìš°íŒ…
        workflow.add_conditional_edges(
            "human_review",
            self._route_after_human_review,
            {
                "approved": "completion",
                "retry": "news_analysis",
                "end": END
            }
        )
        
        # ì™„ë£Œ â†’ ì¢…ë£Œ
        workflow.add_edge("completion", END)
        
        # ì»´íŒŒì¼ (ì²´í¬í¬ì¸í„° ë° ì¸í„°ëŸ½íŠ¸ ì„¤ì •)
        return workflow.compile(
            checkpointer=self.checkpointer,
            interrupt_before=["human_review"],  # íœ´ë¨¼ ë¦¬ë·° ì „ ì¤‘ë‹¨
            interrupt_after=["quality_validation"]  # í’ˆì§ˆ ê²€ì¦ í›„ ì¤‘ë‹¨ ê°€ëŠ¥
        )
    
    # === ğŸ¯ 3ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ ì‹¤í–‰ ë…¸ë“œë“¤ (Stage 3) ===
    
    async def _analysis_node(self, state: NewsState) -> NewsState:
        """ğŸ¯ ë‰´ìŠ¤ ë¶„ì„ + íŒ©íŠ¸ì²´í‚¹ ì—ì´ì „íŠ¸ ì‹¤í–‰ (95% ì •í™•ë„ ëª©í‘œ)"""
        try:
            logger.info(f"ğŸ” Starting comprehensive news analysis for article {state.article_id}")
            state = await self.analysis_agent.analyze_trends(state)
            state.add_metric("analysis_completed", True)
            state.add_metric("fact_check_completed", True)
            return state
        except Exception as e:
            logger.error(f"News analysis node failed: {str(e)}")
            state.add_error(f"News analysis failed: {str(e)}")
            return state
    
    async def _personalization_node(self, state: NewsState) -> NewsState:
        """ğŸ¯ ê°œì¸í™” + ìŠ¤í† ë¦¬í…”ë§ ì—ì´ì „íŠ¸ ì‹¤í–‰ (4.5/5.0 ë§Œì¡±ë„ ëª©í‘œ)"""
        try:
            logger.info(f"ğŸ‘¤ Starting personalization + storytelling for article {state.article_id}")
            state = await self.personalization_agent.personalize_content(state)
            state.add_metric("personalization_completed", True)
            state.add_metric("storytelling_completed", True)
            return state
        except Exception as e:
            logger.error(f"Personalization node failed: {str(e)}")
            state.add_error(f"Personalization failed: {str(e)}")
            return state
    
    async def _voice_synthesis_node(self, state: NewsState) -> NewsState:
        """ğŸ¯ ìŒì„± í•©ì„± ì—ì´ì „íŠ¸ ì‹¤í–‰ (í”„ë¡œ ì„±ìš° ìˆ˜ì¤€ í’ˆì§ˆ, ë‹¤ì¤‘ ìºë¦­í„°)"""
        try:
            logger.info(f"ğŸµ Starting voice synthesis for article {state.article_id}")
            state = await self.voice_synthesis_agent.synthesize_voice(state)
            state.add_metric("voice_synthesis_completed", True)
            return state
        except Exception as e:
            logger.error(f"Voice synthesis node failed: {str(e)}")
            state.add_error(f"Voice synthesis failed: {str(e)}")
            return state
    
    # === í’ˆì§ˆ ê²€ì¦ ë° ë¼ìš°íŒ… ë…¸ë“œë“¤ ===
    
    async def _quality_validation_node(self, state: NewsState) -> NewsState:
        """í’ˆì§ˆ ê²€ì¦ ë…¸ë“œ"""
        try:
            logger.info(f"Quality validation for article {state.article_id}")
            
            quality_score = 0.0
            validation_issues = []
            
            # ë¶„ì„ ê²°ê³¼ í’ˆì§ˆ ì²´í¬
            if state.analysis_result:
                if state.analysis_result.trend_score >= 0.7:
                    quality_score += 0.25
                else:
                    validation_issues.append("Low trend analysis score")
            
            # íŒ©íŠ¸ì²´í‚¹ í’ˆì§ˆ ì²´í¬ (95% ëª©í‘œ)
            if state.fact_check_result:
                if state.fact_check_result.credibility_score >= 0.95:
                    quality_score += 0.25
                else:
                    validation_issues.append("Fact check accuracy below 95%")
            
            # ìŠ¤í† ë¦¬í…”ë§ í’ˆì§ˆ ì²´í¬
            if state.storytelling_result:
                if state.storytelling_result.engagement_score >= 4.2:
                    quality_score += 0.25
                else:
                    validation_issues.append("Low storytelling engagement")
            
            # ìŒì„± í•©ì„± í’ˆì§ˆ ì²´í¬
            if state.voice_synthesis_result:
                if state.voice_synthesis_result.synthesis_quality >= 0.8:
                    quality_score += 0.25
                else:
                    validation_issues.append("Low voice synthesis quality")
            
            state.add_metric("overall_quality_score", quality_score)
            state.add_metric("validation_issues", validation_issues)
            
            return state
            
        except Exception as e:
            logger.error(f"Quality validation failed: {str(e)}")
            state.add_error(f"Quality validation error: {str(e)}")
            return state
    
    async def _human_review_node(self, state: NewsState) -> NewsState:
        """íœ´ë¨¼ ë¦¬ë·° ë…¸ë“œ"""
        logger.info(f"Human review required for article {state.article_id}")
        state.update_stage(ProcessingStage.HUMAN_REVIEW)
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì—¬ê¸°ì„œ ëŒ€ê¸°í•˜ê³  ì™¸ë¶€ ìŠ¹ì¸ì„ ë°›ìŒ
        return state
    
    async def _completion_node(self, state: NewsState) -> NewsState:
        """ì™„ë£Œ ë…¸ë“œ"""
        try:
            logger.info(f"Completing processing for article {state.article_id}")
            state.update_stage(ProcessingStage.COMPLETED)
            state.completed_at = datetime.utcnow()
            
            total_time = (state.completed_at - state.created_at).total_seconds()
            state.add_metric("total_processing_time", total_time)
            
            return state
        except Exception as e:
            logger.error(f"Completion node failed: {str(e)}")
            state.add_error(f"Completion error: {str(e)}")
            return state
    
    # === ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜ë“¤ ===
    
    def _should_proceed_after_analysis(self, state: NewsState) -> Literal["continue", "quality_check", "human_review", "end"]:
        """ğŸ¯ ë‰´ìŠ¤ ë¶„ì„ + íŒ©íŠ¸ì²´í‚¹ í›„ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •"""
        if state.errors:
            return "end"
        
        if not state.trend_analysis_result:
            return "quality_check"
        
        # 95% íŒ©íŠ¸ì²´í‚¹ ì •í™•ë„ ê¸°ì¤€ ê²€ì¦
        if hasattr(state, 'fact_check_result') and state.fact_check_result:
            if state.fact_check_result.credibility_score < 0.95:
                logger.warning(f"Low credibility score: {state.fact_check_result.credibility_score}")
                return "human_review"
        
        if state.trend_analysis_result.trending_score < 0.5:
            return "human_review"
        
        return "continue"
    
    def _should_proceed_after_personalization(self, state: NewsState) -> Literal["continue", "quality_check", "human_review", "end"]:
        """ğŸ¯ ê°œì¸í™” + ìŠ¤í† ë¦¬í…”ë§ í›„ ë‹¤ìŒ ë‹¨ê³„ ê²°ì • (4.5/5.0 ë§Œì¡±ë„ ëª©í‘œ)"""
        if state.errors:
            return "end"
        
        if not state.personalization_result:
            return "quality_check"
        
        # 4.5/5.0 ê°œì¸í™” ë§Œì¡±ë„ ëª©í‘œ ê²€ì¦
        if hasattr(state.personalization_result, 'personalization_score') and \
           hasattr(state.personalization_result.personalization_score, 'overall_score'):
            if state.personalization_result.personalization_score.overall_score < 4.5:
                logger.warning(f"Low personalization score: {state.personalization_result.personalization_score.overall_score}")
                return "quality_check"
        
        return "continue"
    
    def _should_proceed_after_voice_synthesis(self, state: NewsState) -> Literal["continue", "quality_check", "human_review", "end"]:
        """ìŒì„± í•©ì„± í›„ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •"""
        if state.errors:
            return "end"
        
        if not state.voice_synthesis_result:
            return "quality_check"
        
        if state.voice_synthesis_result.synthesis_quality < 0.7:
            return "human_review"
        
        return "continue"
    
    def _route_after_quality_check(self, state: NewsState) -> Literal["retry_analysis", "retry_personalization", "retry_voice", "human_review", "continue", "end"]:
        """ğŸ¯ í’ˆì§ˆ ê²€ì¦ í›„ ë¼ìš°íŒ… (3ê°œ ì—ì´ì „íŠ¸)"""
        quality_score = state.metrics.get("overall_quality_score", 0.0)
        validation_issues = state.metrics.get("validation_issues", [])
        
        if quality_score >= 0.8:
            return "continue"
        
        if quality_score < 0.3:
            return "end"
        
        # ğŸ¯ 3ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ ì¬ì‹¤í–‰ ë¶„ê¸°
        if "Low news analysis score" in validation_issues or "Fact check accuracy below 95%" in validation_issues:
            return "retry_analysis"
        elif "Low personalization score" in validation_issues or "Low storytelling engagement" in validation_issues:
            return "retry_personalization"
        elif "Low voice synthesis quality" in validation_issues:
            return "retry_voice"
        
        return "human_review"
    
    def _route_after_human_review(self, state: NewsState) -> Literal["approved", "retry", "end"]:
        """íœ´ë¨¼ ë¦¬ë·° í›„ ë¼ìš°íŒ…"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì™¸ë¶€ ìŠ¹ì¸ ìƒíƒœë¥¼ í™•ì¸
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
        human_decision = state.metrics.get("human_review_decision", "approved")
        
        if human_decision == "approved":
            return "approved"
        elif human_decision == "retry":
            return "retry"
        else:
            return "end"
    
    # === ë©”ì¸ ì‹¤í–‰ ì¸í„°í˜ì´ìŠ¤ ===
    
    async def process_news(self, article_id: str, content: str, title: str = "", 
                          user_id: Optional[str] = None, config: Optional[Dict] = None) -> NewsState:
        """
        ğŸ¯ ë‰´ìŠ¤ ì²˜ë¦¬ ë©”ì¸ ì§„ì…ì  (Stage 3)
        3ê°œ ì „ë¬¸ ì—ì´ì „íŠ¸ ìˆœì°¨ ì‹¤í–‰: ë‰´ìŠ¤ë¶„ì„(+íŒ©íŠ¸ì²´í‚¹) â†’ ê°œì¸í™”(+ìŠ¤í† ë¦¬í…”ë§) â†’ ìŒì„±í•©ì„±
        """
        try:
            # ì²˜ë¦¬ ì„¸ì…˜ ID ìƒì„±
            processing_id = str(uuid4())
            
            # ì´ˆê¸° ìƒíƒœ ìƒì„±
            initial_state = NewsState(
                article_id=article_id,
                user_id=user_id,
                processing_id=processing_id,
                title=title,
                content=content,
                processing_stage=ProcessingStage.INITIATED
            )
            
            # Langfuse ì¶”ì  ì‹œì‘
            trace = self.langfuse.trace(
                name="newstalk_ai_workflow",
                input={
                    "article_id": article_id,
                    "user_id": user_id,
                    "content_length": len(content),
                    "title": title
                }
            )
            
            logger.info(f"Starting NewsTalk AI processing for article {article_id}")
            
            # ê·¸ë˜í”„ ì„¤ì •
            graph_config = {
                "configurable": {
                    "thread_id": processing_id,
                    "checkpoint_ns": f"newstalk_{article_id}",
                    **(config or {})
                }
            }
            
            # ê·¸ë˜í”„ ì‹¤í–‰
            final_state = None
            async for state in self.graph.astream(initial_state, config=graph_config):
                final_state = state
                logger.debug(f"Processing stage: {state.processing_stage}")
            
            # ì¶”ì  ì™„ë£Œ
            trace.update(
                output={
                    "processing_stage": final_state.processing_stage.value,
                    "completed": final_state.processing_stage == ProcessingStage.COMPLETED,
                    "total_time": final_state.metrics.get("total_processing_time", 0),
                    "quality_score": final_state.metrics.get("overall_quality_score", 0),
                    "errors": len(final_state.errors) if final_state.errors else 0
                }
            )
            
            logger.info(f"NewsTalk AI processing completed for article {article_id} - Stage: {final_state.processing_stage}")
            return final_state
            
        except Exception as e:
            logger.error(f"NewsTalk AI processing failed for article {article_id}: {str(e)}")
            # ì—ëŸ¬ ìƒíƒœ ë°˜í™˜
            error_state = NewsState(
                article_id=article_id,
                processing_id=processing_id,
                processing_stage=ProcessingStage.FAILED
            )
            error_state.add_error(f"Workflow error: {str(e)}")
            return error_state

    def get_processing_stats(self) -> Dict:
        """ğŸ¯ ì²˜ë¦¬ í†µê³„ ë°˜í™˜ (Stage 3)"""
        return {
            "agents_count": 3,
            "agents": [
                "AnalysisAgent (News Analysis + Fact Checking)",
                "PersonalizationAgent (Personalization + Storytelling)", 
                "VoiceSynthesisAgent (Multi-Character Voice)"
            ],
            "quality_targets": {
                "fact_check_accuracy": "95%",
                "personalization_satisfaction": "4.5/5.0",
                "storytelling_engagement": "4.2/5.0",
                "voice_synthesis_quality": "Pro-level"
            },
            "workflow": "News Analysis â†’ Personalization â†’ Voice Synthesis",
            "checkpoint_enabled": True,
            "human_review_supported": True,
            "stage": "Stage 3"
        } 