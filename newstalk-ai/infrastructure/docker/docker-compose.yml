version: '3.8'

# Stage 8: Production-Ready Docker Compose Configuration
services:
  # Database with resource limits and optimizations
  postgres:
    image: postgres:16-alpine
    container_name: newstalk-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: newstalk_ai
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d newstalk_ai"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Redis 8.0 Cache with TimeSeries and resource optimization
  redis:
    image: redis/redis-stack:7.2.0-v7
    container_name: newstalk-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
      - "8001:8001"  # RedisInsight UI
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf --maxmemory 512mb --maxmemory-policy allkeys-lru
    environment:
      - REDIS_ARGS="--appendonly yes --appendfsync everysec"
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 768M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Zookeeper with resource limits
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: newstalk-zookeeper
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_HEAP_OPTS: "-Xmx512M -Xms256M"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 768M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Kafka with enhanced performance and resource management
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: newstalk-kafka
    restart: unless-stopped
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9101:9101"  # JMX port for monitoring
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      # Performance settings
      KAFKA_COMPRESSION_TYPE: gzip
      KAFKA_LOG_RETENTION_HOURS: 168  # 7 days
      KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1GB
      KAFKA_LOG_SEGMENT_BYTES: 104857600  # 100MB
      KAFKA_LOG_CLEANUP_POLICY: delete
      # JVM settings
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms512M"
      # JMX monitoring
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Airflow Database with optimizations
  airflow-postgres:
    image: postgres:16-alpine
    container_name: newstalk-airflow-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: airflow
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow123
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Airflow Webserver with production settings
  airflow-webserver:
    build:
      context: ../../backend
      dockerfile: ../infrastructure/docker/Dockerfile.airflow
      args:
        BUILD_ENV: production
    container_name: newstalk-airflow-webserver
    restart: unless-stopped
    depends_on:
      airflow-postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - AIRFLOW_SERVICE=webserver
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow123@airflow-postgres/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow123@airflow-postgres/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
      - AIRFLOW__WEBSERVER__SECRET_KEY=your-secret-key-here
    volumes:
      - ../../backend/airflow/dags:/opt/airflow/dags
      - ../../backend/airflow/logs:/opt/airflow/logs
      - ../../backend/airflow/plugins:/opt/airflow/plugins
    ports:
      - "8081:8080"
    command: webserver
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Airflow Scheduler with production settings
  airflow-scheduler:
    build:
      context: ../../backend
      dockerfile: ../infrastructure/docker/Dockerfile.airflow
      args:
        BUILD_ENV: production
    container_name: newstalk-airflow-scheduler
    restart: unless-stopped
    depends_on:
      airflow-postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - AIRFLOW_SERVICE=scheduler
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow123@airflow-postgres/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow123@airflow-postgres/airflow  
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
    volumes:
      - ../../backend/airflow/dags:/opt/airflow/dags
      - ../../backend/airflow/logs:/opt/airflow/logs
      - ../../backend/airflow/plugins:/opt/airflow/plugins
    command: scheduler
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # Airflow Worker with resource limits
  airflow-worker:
    build:
      context: ../../backend
      dockerfile: ../infrastructure/docker/Dockerfile.airflow
      args:
        BUILD_ENV: production
    container_name: newstalk-airflow-worker
    restart: unless-stopped
    depends_on:
      airflow-postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - AIRFLOW_SERVICE=worker
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow123@airflow-postgres/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:airflow123@airflow-postgres/airflow  
      - AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY=
      - AIRFLOW__CELERY__WORKER_CONCURRENCY=4
    volumes:
      - ../../backend/airflow/dags:/opt/airflow/dags
      - ../../backend/airflow/logs:/opt/airflow/logs
      - ../../backend/airflow/plugins:/opt/airflow/plugins
    command: celery worker
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

  # FastAPI Backend with production configuration
  fastapi-backend:
    build:
      context: ../../backend
      dockerfile: ../infrastructure/docker/Dockerfile.backend
      args:
        BUILD_ENV: production
    container_name: newstalk-fastapi
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      - DATABASE_URL=postgresql://postgres:postgres123@postgres:5432/newstalk_ai
      - REDIS_URL=redis://redis:6379/0
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - KAFKA_HOST=kafka
      - KAFKA_PORT=29092
      - PIPELINE_MAX_PROCESSING_TIME=300
      - SSE_MAX_CONNECTIONS=1000
      - ENABLE_STREAMING=true
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_HOST=${LANGFUSE_HOST}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
    ports:
      - "8000:8000"
    volumes:
      - ../../backend:/app
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # LangGraph Service with dedicated container
  langgraph-service:
    build:
      context: ../../backend
      dockerfile: ../infrastructure/docker/Dockerfile.langgraph
      args:
        BUILD_ENV: production
    container_name: newstalk-langgraph
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - DATABASE_URL=postgresql://postgres:postgres123@postgres:5432/newstalk_ai
      - REDIS_URL=redis://redis:6379/0
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_HOST=${LANGFUSE_HOST}
    ports:
      - "8001:8001"
    volumes:
      - ../../backend:/app
      - langgraph_checkpoints:/app/checkpoints
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # Stream Processor Service
  stream-processor:
    build:
      context: ../../backend
      dockerfile: ../infrastructure/docker/Dockerfile.stream-processor
      args:
        BUILD_ENV: production
    container_name: newstalk-stream-processor
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - REDIS_URL=redis://redis:6379/0
      - STREAM_PROCESSING_ENABLED=true
      - STREAM_BATCH_SIZE=100
      - STREAM_PROCESSING_INTERVAL=10
    ports:
      - "8002:8002"
    volumes:
      - ../../backend:/app
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # Prometheus Monitoring with resource limits
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: newstalk-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ../monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - ../monitoring/alert_rules.yml:/etc/prometheus/alert_rules.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana Dashboard with optimizations
  grafana:
    image: grafana/grafana:10.1.0
    container_name: newstalk-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=redis-datasource,kafka-datasource
      - GF_RENDERING_SERVER_URL=http://renderer:8081/render
      - GF_RENDERING_CALLBACK_URL=http://grafana:3000/
    volumes:
      - grafana_data:/var/lib/grafana
      - ../monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ../monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Kafka UI for monitoring
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: newstalk-kafka-ui
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: newstalk-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:v1.6.1
    container_name: newstalk-node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.1'

  # cAdvisor for container metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.0
    container_name: newstalk-cadvisor
    restart: unless-stopped
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - newstalk-network
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.3'

volumes:
  postgres_data:
    driver: local
  airflow_postgres_data:
    driver: local
  redis_data:
    driver: local
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  langgraph_checkpoints:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  newstalk-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16 