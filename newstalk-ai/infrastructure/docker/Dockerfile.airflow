# Apache Airflow with Poetry dependency management - Stage 8 Production Ready
FROM apache/airflow:2.8.0-python3.11

# Labels for metadata
LABEL maintainer="NewsTalk AI Team <dev@newstalk.ai>"
LABEL version="1.0.0"
LABEL description="NewsTalk AI Airflow Service with Poetry"

USER root

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    git \
    build-essential \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Switch back to airflow user BEFORE installing Poetry
USER airflow

# Install Poetry as airflow user
ARG POETRY_VERSION=1.7.1
RUN pip install --no-cache-dir poetry==$POETRY_VERSION

# Set working directory
WORKDIR /opt/airflow

# Copy Poetry configuration files
COPY --chown=airflow:airflow pyproject.toml poetry.lock ./

# Export dependencies to requirements.txt using Poetry and install
RUN poetry export -f requirements.txt --output requirements.txt --without-hashes && \
    pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Set environment variables for production
ENV AIRFLOW__CORE__LOAD_EXAMPLES=False \
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True \
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True \
    AIRFLOW__CORE__PARALLELISM=32 \
    AIRFLOW__CORE__DAG_CONCURRENCY=16 \
    AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG=4 \
    AIRFLOW__CELERY__WORKER_CONCURRENCY=4 \
    AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT=60 \
    AIRFLOW__WEBSERVER__WEB_SERVER_WORKER_TIMEOUT=300 \
    PYTHONPATH=/opt/airflow

# Create directories with proper permissions
RUN mkdir -p /opt/airflow/dags /opt/airflow/logs /opt/airflow/plugins /opt/airflow/tmp && \
    chown -R airflow:root /opt/airflow

# Health check for different services
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD if [ "$AIRFLOW_SERVICE" = "webserver" ]; then \
            curl -f http://localhost:8080/health; \
        elif [ "$AIRFLOW_SERVICE" = "scheduler" ]; then \
            airflow jobs check --job-type SchedulerJob --hostname $(hostname); \
        else \
            exit 0; \
        fi 